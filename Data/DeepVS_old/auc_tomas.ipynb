{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve and f1\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from matplotlib import pyplot\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[1,1], random_state=1)\n",
    "#print(X[:3],y[:3])\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# print(probs)\n",
    "# predict class values\n",
    "yhat = model.predict(testX)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(testy, probs)\n",
    "# calculate F1 score\n",
    "print(thresholds)\n",
    "f1 = f1_score(testy, yhat)\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(testy, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created on May 6, 2018\n",
    "@author: jana\n",
    "'''\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from data_processing import load_data, prepareMolData, prepareMinibatches, context_dictionary, loadProteinRestrictions\n",
    "from model import DeepVS\n",
    "from scorer_auc_enrichment_factor import Scorer\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "class DeepVSExperiment:\n",
    "    \n",
    "    def __init__(self,\n",
    "        embedding_size = 200,\n",
    "        cf = 400,\n",
    "        h  = 50,\n",
    "        lr = 0.00001,\n",
    "        kc = 6,\n",
    "        kp = 2,\n",
    "        num_epochs = 7,\n",
    "        minibatchSize = 20,\n",
    "        l2_reg_rate = 0.0001,\n",
    "        use_Adam = True):\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.cf = cf\n",
    "        self.h = h \n",
    "        self.lr = lr\n",
    "        self.kc = kc\n",
    "        self.kp = kp\n",
    "        self.num_epochs = num_epochs \n",
    "        self.minibatchSize = minibatchSize\n",
    "        self.l2_reg_rate = l2_reg_rate\n",
    "        self.use_Adam = use_Adam\n",
    "        \n",
    "        self._aucSumByEpoch       = [0.0]*10\n",
    "        self._EfMaxSumByEpoch     = [0.0]*10\n",
    "        self._Ef2SumByEpoch       = [0.0]*10\n",
    "        self._Ef20SumByEpoch      = [0.0]*10\n",
    "        self._numProteinProcessed = 0\n",
    "        \n",
    "\n",
    "\n",
    "    def run(self, datasetPath, proteinsNames_training, proteinsNames_test, proteinRestrictions):\n",
    "        torch.manual_seed(31)   \n",
    "        rng = random.Random(31)\n",
    "        self.epoch = 0\n",
    "        self._numProteinProcessed += 1.0\n",
    "\n",
    "\n",
    "        testProRestrictions = proteinRestrictions.get(proteinsNames_test[0])\n",
    "        \n",
    "        if testProRestrictions is not None:\n",
    "            i = len(proteinsNames_training) - 1\n",
    "            while i > -1 :\n",
    "                if proteinsNames_training[i] in testProRestrictions:\n",
    "                    del proteinsNames_training[i]\n",
    "                i -= 1\n",
    "            \n",
    "        # Preparing training dataset\n",
    "        print(\"Loading data ...\")\n",
    "        molName_training, molClass_training, molData_training = load_data(datasetPath, self.kc, self.kp,\n",
    "                                                                          proteinsNames_training, rng, randomize = True)\n",
    "        #print(molName_training)\n",
    "        #print(molData_training)\n",
    "        print(\"proteinsNames_training: \", proteinsNames_training)\n",
    "        print(\"Preparing data ...\")\n",
    "        context_to_ix_training = context_dictionary(molData_training)\n",
    "        molData_ix_training = prepareMolData(molData_training, context_to_ix_training)\n",
    "        molDataBatches_training = prepareMinibatches(molData_ix_training, molClass_training, self.minibatchSize)\n",
    "        \n",
    "#         print(\"CLASS\", molClass_training[:20])\n",
    "#         print(\"MOLD DATA TRAINING \", molData_training[:20])\n",
    "#         print(\"CONTEXT_TO_IX_TRAINING FOR MOLDATA \", context_to_ix_training)\n",
    "#         print(\"MOL DATA BATCHES FROM CONTEXT AND CLASS \", molDataBatches_training[:20])\n",
    "        \n",
    "        # Preparing test dataset\n",
    "        molName_test, molClass_test, molData_test = load_data(datasetPath, self.kc, self.kp, proteinsNames_test,\n",
    "                                                              rng, randomize = False)\n",
    "        print(\"proteinsNames_test: \", proteinsNames_test)\n",
    "        print(\"number of test molecules: \", len(molData_test))\n",
    "        molData_ix_test = prepareMolData(molData_test, context_to_ix_training)\n",
    "        molDataBatches_test = prepareMinibatches(molData_ix_test, molClass_test, self.minibatchSize)\n",
    "        #print(proteinsNames_test)\n",
    "        #molDataBatches_test = label_binarize(molDataBatches_test, classes=[0, 1])\n",
    "        #print(molDataBatches_test)\n",
    "        \n",
    "        \n",
    "        # Number of columns in the embedding matrix\n",
    "        vocab_size = len(context_to_ix_training) \n",
    "        \n",
    "        \n",
    "        # Instantiate Model  Class\n",
    "        model = DeepVS(vocab_size, self.embedding_size, self.cf, self.h, self.kc, self.kp)\n",
    "        #print(\"---------VOCAB SIZE----------\", vocab_size)\n",
    "        #print(\"---------EMBEDDING size----------\", self.embedding_size)\n",
    "        #####################\n",
    "        # Use GPU for model #\n",
    "        #####################\n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()  \n",
    "            print(\"using GPU!\")\n",
    "        \n",
    "        \n",
    "        # Instantiate Loss Class\n",
    "        loss_fuction = nn.NLLLoss()\n",
    "        \n",
    "        \n",
    "        # Instantiate scorer\n",
    "        scorer = Scorer()\n",
    "        \n",
    "        # AUC SCORER\n",
    "        # aucscorer = AUCScorer()\n",
    "        \n",
    "        \n",
    "        # Instantiate optimizer class: using Adam\n",
    "        if self.use_Adam:\n",
    "            optimizer  = optim.Adam(model.parameters(), self.lr, weight_decay = self.l2_reg_rate)\n",
    "            print('using Adam')            \n",
    "        else:\n",
    "            optimizer  = optim.SGD(model.parameters(), self.lr, weight_decay = self.l2_reg_rate)\n",
    "            print('using SGD')\n",
    "        \n",
    "        print('lr = ', self.lr)\n",
    "        print('ls_reg_rate = ', self.l2_reg_rate)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # Train Model\n",
    "        print(\"Training ...\")\n",
    "        for epoch in range(1, self.num_epochs+1):\n",
    "            total_loss = 0.0\n",
    "            model.train()\n",
    "            for cmplx, cls, msk in molDataBatches_training:\n",
    "                # convert contexts and classes into torch variables \n",
    "                if torch.cuda.is_available():\n",
    "                    cls  = autograd.Variable(torch.LongTensor(cls).cuda())\n",
    "                    cmplx = autograd.Variable(torch.LongTensor(cmplx).cuda())\n",
    "                    mskv = autograd.Variable(torch.FloatTensor(msk).cuda())                  \n",
    "                else:\n",
    "                    cls  = autograd.Variable(torch.LongTensor(cls))\n",
    "                    cmplx = autograd.Variable(torch.LongTensor(cmplx))\n",
    "                    mskv = autograd.Variable(torch.FloatTensor(msk))\n",
    "        \n",
    "                model.zero_grad()\n",
    "                                \n",
    "                # Run the forwad pass \n",
    "                log_probs = model(cmplx, mskv)\n",
    "                \n",
    "                # Compute loss and update model \n",
    "                loss = loss_fuction(log_probs,cls)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.data.cpu()        \n",
    "            \n",
    "            # shuffles the training set after each epoch\n",
    "            rng.shuffle(molDataBatches_training)\n",
    "            #rng.shuffle(molDataBatches_test)\n",
    "            \n",
    "            # sets model to eval (needed to use dropout in eval mode)\n",
    "            model.eval()\n",
    "            # Test model after each epoch\n",
    "            correct = 0.0\n",
    "            numberOfMolecules = 0.0\n",
    "            total_loss_test = 0.0\n",
    "            scores = []\n",
    "            scr = []\n",
    "            cls = []\n",
    "            testMolId = 0\n",
    "           # print(molDataBatches_test)\n",
    "            for cmplx_test, cls_test, msk_test in molDataBatches_test:\n",
    "               \n",
    "                cls_test  = torch.LongTensor(cls_test)\n",
    "                #print(cls_test)\n",
    "                #print(cls_test)\n",
    "                # convert contexts and classes into torch variables\n",
    "                if torch.cuda.is_available():     \n",
    "                    cls_test_v = autograd.Variable(cls_test.cuda())\n",
    "                    cmplx_test = autograd.Variable(torch.LongTensor(cmplx_test).cuda())\n",
    "                    mskv_test = autograd.Variable(torch.FloatTensor(msk_test).cuda())             \n",
    "                else:\n",
    "                    cls_test_v = autograd.Variable(cls_test)\n",
    "                    cmplx_test = autograd.Variable(torch.LongTensor(cmplx_test))\n",
    "                    mskv_test = autograd.Variable(torch.FloatTensor(msk_test)) \n",
    "                \n",
    "                # Run the forwad pass \n",
    "                outputs = model(cmplx_test, mskv_test)\n",
    "                loss_test = loss_fuction(outputs, cls_test_v)\n",
    "                #print(outputs)\n",
    "                #print(loss_test)\n",
    "                \n",
    "\n",
    "                #print(auc)\n",
    "                # Get predictions \n",
    "                #print(outputs.data)\n",
    "                #predict_mine = np.where(outputs.data > torch.LongTensor(0.3), torch.LongTensor(1), torch.LongTensor(0))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                #print(\"_, predicted \", _, predicted)\n",
    "\n",
    "                for cur_scr, cur_cls in zip(np.exp(outputs.data[:,1]), cls_test.cpu()):\n",
    "                    scr.append(cur_scr)\n",
    "                    cls.append(cur_cls)\n",
    "                    scores.append([cur_scr, cur_cls, molName_test[testMolId]])\n",
    "                    #print(cur_scr)\n",
    "                    testMolId += 1\n",
    "                numberOfMolecules += cls_test.size()[0]\n",
    "                \n",
    "                \n",
    "               \n",
    "                \n",
    "                      \n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == cls_test.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == cls_test).sum()\n",
    "                    print(\"If predicted: \", predicted)\n",
    "                    print(\"equals to test class: \",cls_test)\n",
    "                    print(\"Correct = \", correct)\n",
    "                    print(\"----------\")      \n",
    "                total_loss_test += loss_test.data\n",
    "                \n",
    "#             print(\"Total correct: \", correct)\n",
    "            accuracy = 100 * correct / numberOfMolecules\n",
    "            print(\"--------------------------------------------------------------------------------------------\")    \n",
    "            print(\"epoch = %d;  total loss training = %.4f; total loss test = %.4f; accuracy = %f\" %(epoch, total_loss/len(molDataBatches_training), total_loss_test/len(molDataBatches_test), accuracy))\n",
    "            efAll, dataForROCCurve, efValues, aucValue = scorer.computeEnrichmentFactor_and_AUC(scores,removeRepetitions=True)\n",
    "#             aucScorer = AUCScorer(scoresToAuc)\n",
    "            # -----\n",
    "            # AUC\n",
    "            # -----\n",
    "            pos_0_scr= [x[0] for x in scores]\n",
    "            pos_1_cls= [x[1] for x in scores]\n",
    "\n",
    "            precision, recall, thresholds = precision_recall_curve(pos_1_cls, pos_0_scr) # cls, scr\n",
    "\n",
    "            auc_score = auc(recall, precision)\n",
    "            print(\"New AUC score: \", auc_score)\n",
    "            \n",
    "            # ---------\n",
    "            # ROC curve\n",
    "            # ---------\n",
    "#----\n",
    "#             scorer.plotROCCurve(dataForROCCurve, pos_1_cls)\n",
    "#----\n",
    "#----        \n",
    "#             plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "#             # plot the precision-recall curve for the model\n",
    "#             plt.plot(recall, precision, marker='.')\n",
    "#             # show the plot\n",
    "#             plt.show()\n",
    "#---            \n",
    "#----            \n",
    "#             fpr, tpr, thresholds = roc_curve(pos_1_cls, pos_0_scr)\n",
    "#             roc_auc = auc(fpr, tpr)\n",
    "#             plt.figure()\n",
    "#             plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "#             plt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\n",
    "#             plt.xlim([0.0, 1.0])\n",
    "#             plt.ylim([0.0, 1.05])\n",
    "#             plt.xlabel('False Positive Rate')\n",
    "#             plt.ylabel('True Positive Rate')\n",
    "#             plt.title('Receiver operating characteristic')\n",
    "#             plt.legend(loc=\"lower right\")\n",
    "#             plt.show()\n",
    "#----\n",
    "\n",
    "            self._aucSumByEpoch[self.epoch]    += auc_score #aucValue\n",
    "            self._EfMaxSumByEpoch[self.epoch]  += efValues[2]\n",
    "            self._Ef2SumByEpoch[self.epoch]    += efValues[0]\n",
    "            self._Ef20SumByEpoch[self.epoch]   += efValues[1]\n",
    "            \n",
    "            self.epoch += 1\n",
    "            \n",
    "            # -------\n",
    "            # Confusion matrix\n",
    "            # -------\n",
    "#             print(accuracy_score(pos_1_cls, pos_0_scr))\n",
    "#             print(confusion_matrix(pos_1_cls, pos_0_scr))\n",
    "#             print(classification_report(pos_1_cls, pos_0_scr))\n",
    "#             print(\"--------------Confusion matrix from DeepVS threshold = 0.5--------------\")\n",
    "            #aucScorer.confusion_matrix(threshold=0.5,do_print=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "        print(\"Average AUC, EF2, EF20, EFMax by epoch for %d proteins:\"%self._numProteinProcessed)\n",
    "        for k in range(self.num_epochs):\n",
    "            print(\"Ep: %d, AUC: %.4f -\"%(k+1, self._aucSumByEpoch[k]/self._numProteinProcessed), end=' ')\n",
    "        print(\" \")\n",
    "        for k in range(self.num_epochs):\n",
    "            print(\"Ep: %d, EF 2%%: %.4f -\"%(k+1, self._Ef2SumByEpoch[k]/self._numProteinProcessed), end=' ')\n",
    "        print(\" \")\n",
    "        for k in range(self.num_epochs):\n",
    "            print(\"Ep: %d, EF 20%%: %.4f -\"%(k+1, self._Ef20SumByEpoch[k]/self._numProteinProcessed), end=' ')\n",
    "        print(\" \")\n",
    "        for k in range(self.num_epochs):\n",
    "            print(\"Ep: %d, EF Max: %.4f -\"%(k+1, self._EfMaxSumByEpoch[k]/self._numProteinProcessed), end=' ')\n",
    "        print(\" \")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    '''\n",
    "    Definition of Hyperparameters:\n",
    "    \n",
    "    embedding_size = embedding size of d^atm, d^amino, d^chg, d^dist\n",
    "    cf = number of convolutional filters\n",
    "    h =  number of hidden units\n",
    "    lr = learning rate\n",
    "    kc = number of neighboring atoms from compound\n",
    "    kp = number of neighboring atoms from protein\n",
    "    num_epoch = number of epochs\n",
    "    '''\n",
    "\n",
    "    \n",
    "    dvsExp = DeepVSExperiment(\n",
    "        embedding_size = 200,\n",
    "        cf = 400,\n",
    "        h  = 50,\n",
    "        lr = 0.00001,\n",
    "        kc = 6,\n",
    "        kp = 2,\n",
    "        num_epochs = 7,\n",
    "        minibatchSize = 20,\n",
    "        l2_reg_rate = 0.0001,\n",
    "        use_Adam = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    proteinNames = ['ace', \n",
    "                    'ache', 'ada', 'alr2', 'ampc', 'ar']#, 'cdk2','comt', 'cox1']\n",
    "#                     'cox2', 'dhfr', 'egfr', 'er_agonist', 'er_antagonist', \n",
    "#                     'fgfr1', 'fxa', 'gart', 'gpb', 'gr', 'hivpr', 'hivrt', 'hmga', 'hsp90', 'inha', 'mr', \n",
    "#                     'na', 'p38', 'parp', 'pde5', 'pdgfrb', 'pnp', 'ppar', 'pr', 'rxr', 'sahh', \n",
    "#                     'src', 'thrombin', 'tk', 'trypsin', 'vegfr2']\n",
    "    \n",
    "                    \n",
    "#                     ['3klm', '3tfq', '1a4g', '1a5h', '1adw', '1ah3'\n",
    "#                     ,'1b8o', '1ckp', '1cx2', '1e3g', '1eve', '1f0r', '1fm9', '1hw8', '1i00'\n",
    "#                     ,'1j8f', '1m17', '1nhz', '1ouk', '1p44', '1r4l', '1s3v', '1s6p', '1uou'\n",
    "#                     ,'1uy6', '1uze', '1w4r', '1xjd', '1xoi', '1xp0', '1z11', '2afx', '2b1p'\n",
    "#                     ,'2dg3', '2iwi', '2oo8', '2p1t', '2p54', '2src', '2vgo', '2vwz', '2w31'\n",
    "#                     ,'2w8y', '2wcg', '2xch', '2z94', '3bc3', '3c7q', '3dbs', '3dds', '3elj'\n",
    "#                     ,'3eml', '3ewj', '3fdn', '3frg', '3hng', '3i4b', '3k5e', '3kc3', '3kk6'\n",
    "#                     ,'3kx1', '3l3m', '3lbk', '3lxl', '3max', '3mhw', '3mj1', '3mpm', '3npc'\n",
    "#                     ,'3nu3', '3nw7', '3ny9', '3oll', '3pp0', '3qkl', '3r04', '3rm2', '3sff'\n",
    "#                     ,'3skc', '3v8s']\n",
    "    \n",
    "    \n",
    "                    #['3tfq', '1a5h']\n",
    "                    # ace\n",
    "                    #'ache', 'ada', 'alr2', 'ampc', 'ar', 'cdk2','comt', 'cox1', \n",
    "                    #'cox2', 'dhfr', 'egfr', 'er_agonist', 'er_antagonist', \n",
    "                    #'fgfr1', 'fxa', 'gart', 'gpb', 'gr', 'hivpr', 'hivrt', 'hmga', 'hsp90', 'inha', 'mr', \n",
    "                    #'na', 'p38', 'parp', 'pde5', 'pdgfrb', 'pnp', 'ppar', 'pr', 'rxr', 'sahh', \n",
    "                    #'src', 'thrombin', 'tk', 'trypsin', 'vegfr2']\n",
    "    \n",
    "    \n",
    " \n",
    "    datasetPath  = 'dud_vinaout_deepvs/'\n",
    "    proteinGroupsFileName = 'protein.groups' \n",
    "    proteinCrossEnrichmentFileName = 'protein.cross_enrichment'\n",
    "    \n",
    "    \n",
    "    proteinNames = [x for x in proteinNames if os.path.isfile(datasetPath+x+\".deepvs\")]\n",
    "#     print(len(filtered))\n",
    "#     for i, pr in enumerate(proteinNames):\n",
    "# #         if(str(prot).__contains__(\"1hw8\")):\n",
    "# #             print(\"This: \",prot)\n",
    "# #         else:\n",
    "#         print(i, pr)\n",
    "  \n",
    "#         if(not os.path.isfile(datasetPath+pr.strip()+\".deepvs\")):\n",
    "#             #print(\"File does not exist in directory: \", datasetPath+prot+\".deepvs\")\n",
    "#            # print(\"Removing it from the list...\")\n",
    "#             proteinNames.remove(pr)\n",
    "#     print(count)\n",
    "    print(\"New protein Names: \", proteinNames)\n",
    "    print(\"Length of protein list\", len(proteinNames))\n",
    "\n",
    "    proteinRestrictions = loadProteinRestrictions(proteinGroupsFileName,proteinCrossEnrichmentFileName)\n",
    "    \n",
    "    \n",
    "    for pName in proteinNames:\n",
    "        proteinNames_test = []\n",
    "        proteinNames_training = ''\n",
    "        if pName in proteinNames:\n",
    "            proteinNames_test.append(pName)\n",
    "            proteinNames_training = proteinNames[:]\n",
    "            del proteinNames_training[proteinNames_training.index(pName)]\n",
    "            \n",
    "            print(\"======================================================================\")\n",
    "            print(\"Experimental results for protein:\", proteinNames_test)\n",
    "            print(\"======================================================================\")\n",
    "            dvsExp.run(datasetPath, proteinNames_training, proteinNames_test, proteinRestrictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
